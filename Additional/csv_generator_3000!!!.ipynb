{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⚠️ Data setup instructions\n",
    "\n",
    "This notebook generates `apasites_with_negatives.csv` by combining PolyASite positive sites\n",
    "with sampled negative controls and extracting sequence windows from hg38.\n",
    "\n",
    "The required input files are too large for GitHub. To run this notebook locally, make sure\n",
    "you download the following and place them in the **working directory** (same folder as this notebook):\n",
    "\n",
    "1. **PolyASite clusters (hg38)**\n",
    "   - Download: https://polyasite.unibas.ch/download/ (choose hg38 clusters BED)\n",
    "   - Save as: `polyasite_hg38_clusters.bed`\n",
    "\n",
    "2. **hg38 chromosome sizes**\n",
    "   - UCSC file: http://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.chrom.sizes\n",
    "   - Save as: `hg38.chrom.sizes`\n",
    "\n",
    "3. **hg38 genome FASTA**\n",
    "   - Download and unzip (UCSC version with `chr*` names):\n",
    "     ```bash\n",
    "     curl -L https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/latest/hg38.fa.gz -o hg38.fa.gz\n",
    "     gunzip -f hg38.fa.gz\n",
    "     ```\n",
    "   - This creates `hg38.fa`\n",
    "\n",
    "4. **FASTA index**\n",
    "   - Required for fast random access:\n",
    "     ```bash\n",
    "     samtools faidx hg38.fa\n",
    "     ```\n",
    "   - This creates `hg38.fa.fai` alongside `hg38.fa`\n",
    "\n",
    "---\n",
    "\n",
    "After downloading, you should have these files in the notebook directory:\n",
    "\n",
    "- `polyasite_hg38_clusters.bed`\n",
    "- `hg38.chrom.sizes`\n",
    "- `hg38.fa`\n",
    "- `hg38.fa.fai`\n",
    "\n",
    "The notebook will then generate:\n",
    "- `apasites_with_negatives.csv` → balanced positives and negatives with sequence windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --positives POSITIVES --chrom-sizes\n",
      "                             CHROM_SIZES --out OUT [--k-neg K_NEG]\n",
      "                             [--min-distance MIN_DISTANCE]\n",
      "                             [--mask-bed MASK_BED] [--primary-only]\n",
      "                             [--skip-alt] [--fasta FASTA]\n",
      "                             [--window-up WINDOW_UP]\n",
      "                             [--window-down WINDOW_DOWN] [--motif-aware]\n",
      "                             [--motif-upstream MOTIF_UPSTREAM]\n",
      "                             [--motif-list MOTIF_LIST] [--seed SEED]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --positives, --chrom-sizes, --out\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/codespaces-blank/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Generate matched negatives for PolyASite positives, normalize chromosome names,\n",
    "and write a strand-oriented sequence window per row.\n",
    "\n",
    "Improvements in this version:\n",
    "- Robust FASTA handling: auto-detects whether FASTA uses 'chr' prefixes and maps names.\n",
    "- Sequence extraction is strand-oriented (reverse-complement for '-' strand).\n",
    "- Optional filtering to primary chromosomes and skipping ALT/unlocalized contigs.\n",
    "\n",
    "Example (notebook or CLI):\n",
    "  python generate_negatives.py \\\n",
    "    --positives polyasite_hg38_clusters.bed \\\n",
    "    --chrom-sizes hg38.chrom.sizes \\\n",
    "    --out apasites_with_negatives.csv \\\n",
    "    --k-neg 1 --min-distance 200 \\\n",
    "    --primary-only --skip-alt \\\n",
    "    --fasta hg38.fa --window-up 200 --window-down 100\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import csv\n",
    "import random\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# ------------------------------\n",
    "# I/O helpers\n",
    "# ------------------------------\n",
    "\n",
    "def read_chrom_sizes(path: str) -> Dict[str, int]:\n",
    "    sizes = {}\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            if not line.strip() or line.startswith(\"#\"):\n",
    "                continue\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 2:\n",
    "                sizes[parts[0]] = int(parts[1])\n",
    "    if not sizes:\n",
    "        raise ValueError(f\"No chromosome sizes parsed from {path}\")\n",
    "    return sizes\n",
    "\n",
    "def parse_bed_line(line: str):\n",
    "    parts = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "    if len(parts) < 3:\n",
    "        return None\n",
    "    chrom = parts[0]\n",
    "    start = int(parts[1])\n",
    "    end = int(parts[2])\n",
    "    name = parts[3] if len(parts) > 3 else \"\"\n",
    "    score = parts[4] if len(parts) > 4 else \"0\"\n",
    "    strand = parts[5] if len(parts) > 5 else \"+\"\n",
    "    return chrom, start, end, name, score, strand\n",
    "\n",
    "# ------------------------------\n",
    "# Chromosome name normalization\n",
    "# ------------------------------\n",
    "\n",
    "PRIMARY_SET_NOCHR = {str(i) for i in range(1, 23)} | {\"X\", \"Y\", \"M\", \"MT\"}\n",
    "PRIMARY_SET_CHR   = {f\"chr{i}\" for i in range(1, 23)} | {\"chrX\", \"chrY\", \"chrM\"}\n",
    "\n",
    "def has_chr_prefix(names: List[str]) -> bool:\n",
    "    return any(n.startswith(\"chr\") for n in names)\n",
    "\n",
    "def looks_alt_or_unlocalized(ch: str) -> bool:\n",
    "    base = ch.replace(\"chr\", \"\")\n",
    "    return (\"_\" in ch) or base.startswith(\"GL\") or base.startswith(\"KI\")\n",
    "\n",
    "def normalize_to_target(ch: str, target_has_chr: bool) -> str:\n",
    "    \"\"\"\n",
    "    Normalize a chromosome name to target 'chr' style and harmonize mito.\n",
    "    \"\"\"\n",
    "    c = ch\n",
    "    if target_has_chr:\n",
    "        if not c.startswith(\"chr\"):\n",
    "            c = \"chr\" + c\n",
    "        if c in {\"chrMT\", \"chrMt\", \"chrm\", \"chrmt\"}:\n",
    "            c = \"chrM\"\n",
    "    else:\n",
    "        if c.startswith(\"chr\"):\n",
    "            c = c[3:]\n",
    "        if c.upper() == \"MT\":\n",
    "            c = \"M\"\n",
    "    return c\n",
    "\n",
    "def build_bed_chrom_mapper(sizes_keys: List[str], bed_keys: List[str]) -> Dict[str, str]:\n",
    "    sizes_has_chr = has_chr_prefix(sizes_keys)\n",
    "    mapper = {}\n",
    "    for bch in bed_keys:\n",
    "        mapper[bch] = normalize_to_target(bch, sizes_has_chr)\n",
    "    return mapper\n",
    "\n",
    "# ------------------------------\n",
    "# FASTA chrom-style helpers\n",
    "# ------------------------------\n",
    "\n",
    "def fasta_has_chr_prefix(fa) -> bool:\n",
    "    try:\n",
    "        for k in fa.keys():\n",
    "            # As soon as we see a key, decide\n",
    "            return k.startswith(\"chr\")\n",
    "    except Exception:\n",
    "        return False\n",
    "    return False\n",
    "\n",
    "def normalize_for_fasta(ch: str, fasta_target_has_chr: bool) -> str:\n",
    "    \"\"\"\n",
    "    Translate a normalized BED/CSV chrom name to the style used by the FASTA.\n",
    "    \"\"\"\n",
    "    return normalize_to_target(ch, fasta_target_has_chr)\n",
    "\n",
    "# ------------------------------\n",
    "# BED readers using normalization and filters\n",
    "# ------------------------------\n",
    "\n",
    "def read_bed_points(\n",
    "    path: str,\n",
    "    chrom_mapper: Dict[str, str],\n",
    "    primary_only: bool,\n",
    "    skip_alt: bool,\n",
    "    assume_strand_plus_if_missing: bool = True,\n",
    ") -> Dict[str, List[Tuple[int, str, str]]]:\n",
    "    \"\"\"\n",
    "    Convert BED intervals to cleavage points:\n",
    "      if strand \"+\": pos = end - 1\n",
    "      if strand \"-\": pos = start\n",
    "    Returns dict: chrom -> list of (pos, strand, name) using *normalized* chrom keys.\n",
    "    \"\"\"\n",
    "    d = defaultdict(list)\n",
    "\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            line=line.strip()\n",
    "            if not line or line.startswith(\"#\") or line.startswith(\"track\"):\n",
    "                continue\n",
    "            rec = parse_bed_line(line)\n",
    "            if rec is None:\n",
    "                continue\n",
    "            chrom, start, end, name, score, strand = rec\n",
    "\n",
    "            norm_chrom = chrom_mapper.get(chrom, chrom)\n",
    "\n",
    "            if primary_only:\n",
    "                if has_chr_prefix([norm_chrom]):\n",
    "                    if norm_chrom not in PRIMARY_SET_CHR:\n",
    "                        continue\n",
    "                else:\n",
    "                    if norm_chrom not in PRIMARY_SET_NOCHR:\n",
    "                        continue\n",
    "\n",
    "            if skip_alt and looks_alt_or_unlocalized(norm_chrom):\n",
    "                continue\n",
    "\n",
    "            if strand not in [\"+\", \"-\"]:\n",
    "                strand = \"+\" if assume_strand_plus_if_missing else strand\n",
    "\n",
    "            pos = end - 1 if strand == \"+\" else start\n",
    "            d[norm_chrom].append((pos, strand, name))\n",
    "\n",
    "    for c in d:\n",
    "        d[c].sort(key=lambda x: x[0])\n",
    "\n",
    "    if not d:\n",
    "        sys.stderr.write(\n",
    "            \"[WARN] No BED points loaded after normalization/filters. \"\n",
    "            \"Check chromosome styles or filters.\\n\"\n",
    "        )\n",
    "    return d\n",
    "\n",
    "def read_bed_regions(\n",
    "    path: str,\n",
    "    chrom_mapper: Dict[str, str],\n",
    "    primary_only: bool,\n",
    "    skip_alt: bool,\n",
    ") -> Dict[str, List[Tuple[int,int,str]]]:\n",
    "    d = defaultdict(list)\n",
    "    rid = 0\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            line=line.strip()\n",
    "            if not line or line.startswith(\"#\") or line.startswith(\"track\"):\n",
    "                continue\n",
    "            rec = parse_bed_line(line)\n",
    "            if rec is None:\n",
    "                continue\n",
    "            chrom, start, end, name, score, strand = rec\n",
    "\n",
    "            norm_chrom = chrom_mapper.get(chrom, chrom)\n",
    "\n",
    "            if primary_only:\n",
    "                if has_chr_prefix([norm_chrom]):\n",
    "                    if norm_chrom not in PRIMARY_SET_CHR:\n",
    "                        continue\n",
    "                else:\n",
    "                    if norm_chrom not in PRIMARY_SET_NOCHR:\n",
    "                        continue\n",
    "\n",
    "            if skip_alt and looks_alt_or_unlocalized(norm_chrom):\n",
    "                continue\n",
    "\n",
    "            region_id = name if name else f\"region_{rid}\"\n",
    "            rid += 1\n",
    "            d[norm_chrom].append((start, end, region_id))\n",
    "\n",
    "    for c in d:\n",
    "        d[c].sort()\n",
    "    return d\n",
    "\n",
    "# ------------------------------\n",
    "# Interval / sampling helpers\n",
    "# ------------------------------\n",
    "\n",
    "def build_positive_buffers(positives: List[int], min_distance: int) -> List[Tuple[int,int]]:\n",
    "    intervals = []\n",
    "    for p in positives:\n",
    "        s = max(0, p - min_distance)\n",
    "        e = p + min_distance + 1\n",
    "        intervals.append((s,e))\n",
    "    if not intervals:\n",
    "        return intervals\n",
    "    intervals.sort()\n",
    "    merged = [intervals[0]]\n",
    "    for s,e in intervals[1:]:\n",
    "        ps,pe = merged[-1]\n",
    "        if s <= pe:\n",
    "            merged[-1] = (ps, max(pe, e))\n",
    "        else:\n",
    "            merged.append((s,e))\n",
    "    return merged\n",
    "\n",
    "def contains_pos(intervals: List[Tuple[int,int]], pos: int) -> bool:\n",
    "    lo, hi = 0, len(intervals)\n",
    "    while lo < hi:\n",
    "        mid = (lo+hi)//2\n",
    "        if intervals[mid][0] <= pos:\n",
    "            lo = mid + 1\n",
    "        else:\n",
    "            hi = mid\n",
    "    for i in range(max(0, lo-5), min(len(intervals), lo+5)):\n",
    "        s,e = intervals[i]\n",
    "        if s <= pos < e:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# ------------------------------\n",
    "# Sequence helpers\n",
    "# ------------------------------\n",
    "\n",
    "_RC = str.maketrans({\"A\":\"T\",\"T\":\"A\",\"G\":\"C\",\"C\":\"G\",\"N\":\"N\"})\n",
    "\n",
    "def reverse_complement(seq: str) -> str:\n",
    "    return seq.translate(_RC)[::-1]\n",
    "\n",
    "def _fa_ok(fa) -> bool:\n",
    "    return (fa is not None) and hasattr(fa, \"get_seq\")\n",
    "\n",
    "def _extract_seq_upper(fa, chrom, start_1based, end_inclusive):\n",
    "    \"\"\"\n",
    "    pyfaidx can return either an object with `.seq` or a plain str (when as_raw=True).\n",
    "    Normalize to an uppercase A/C/G/T/N string here.\n",
    "    \"\"\"\n",
    "    res = fa.get_seq(chrom, start_1based, end_inclusive)\n",
    "    s = res.seq if hasattr(res, \"seq\") else str(res)\n",
    "    s = s.upper()\n",
    "    # keep only A/C/G/T/N\n",
    "    return \"\".join(c if c in \"ACGTN\" else \"N\" for c in s)\n",
    "\n",
    "def fetch_window_seq(\n",
    "    fa,\n",
    "    chrom: str,\n",
    "    pos: int,\n",
    "    strand: str,\n",
    "    up: int,\n",
    "    down: int,\n",
    "    chrom_len: Optional[int],\n",
    "    fasta_target_has_chr: Optional[bool]\n",
    ") -> str:\n",
    "    if fa is None or not hasattr(fa, \"get_seq\") or chrom_len is None:\n",
    "        return \"\"\n",
    "    ch_for_fa = normalize_for_fasta(chrom, bool(fasta_target_has_chr))\n",
    "    start = max(0, pos - up)\n",
    "    end   = min(chrom_len, pos + down)\n",
    "    if end <= start:\n",
    "        return \"\"\n",
    "    try:\n",
    "        # pyfaidx coordinates are 1-based inclusive\n",
    "        s = _extract_seq_upper(fa, ch_for_fa, start + 1, end)\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "    if strand == \"-\":\n",
    "        s = reverse_complement(s)\n",
    "    return s\n",
    "\n",
    "def motif_present_upstream(\n",
    "    fa,\n",
    "    chrom: str,\n",
    "    pos: int,\n",
    "    strand: str,\n",
    "    upstream_len: int,\n",
    "    motifs: List[str],\n",
    "    fasta_target_has_chr: Optional[bool]\n",
    ") -> bool:\n",
    "    if fa is None or not hasattr(fa, \"get_seq\"):\n",
    "        return False\n",
    "    ch_for_fa = normalize_for_fasta(chrom, bool(fasta_target_has_chr))\n",
    "    start = max(0, pos - upstream_len)\n",
    "    end = pos\n",
    "    if start >= end:\n",
    "        return False\n",
    "    try:\n",
    "        seq = _extract_seq_upper(fa, ch_for_fa, start + 1, end)\n",
    "    except Exception:\n",
    "        return False\n",
    "    if strand == \"-\":\n",
    "        seq = reverse_complement(seq)\n",
    "    seq = seq.replace(\"U\",\"T\")\n",
    "    for m in motifs:\n",
    "        if m and m.upper().replace(\"U\",\"T\") in seq:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# ------------------------------\n",
    "# Main\n",
    "# ------------------------------\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser(description=\"Generate matched negatives for PolyASite positives.\")\n",
    "    ap.add_argument(\"--positives\", required=True, help=\"PolyASite BED (BED3/BED6), hg38\")\n",
    "    ap.add_argument(\"--chrom-sizes\", required=True, help=\"chrom sizes TSV (chrom\\\\tlength)\")\n",
    "    ap.add_argument(\"--out\", required=True, help=\"Output CSV\")\n",
    "\n",
    "    ap.add_argument(\"--k-neg\", type=int, default=1, help=\"Negatives per positive\")\n",
    "    ap.add_argument(\"--min-distance\", type=int, default=200, help=\"Min distance from any positive (bp)\")\n",
    "\n",
    "    ap.add_argument(\"--mask-bed\", default=None, help=\"Optional BED to constrain where negatives can be sampled (e.g., 3'UTRs)\")\n",
    "    ap.add_argument(\"--primary-only\", action=\"store_true\", help=\"Keep only primary chromosomes (1–22, X, Y, M/MT)\")\n",
    "    ap.add_argument(\"--skip-alt\", action=\"store_true\", help=\"Skip ALT/unlocalized contigs (contain '_' or start with GL/KI)\")\n",
    "\n",
    "    ap.add_argument(\"--fasta\", default=None, help=\"Optional hg38 FASTA for sequence extraction & motif-aware filtering\")\n",
    "    ap.add_argument(\"--window-up\", type=int, default=200, help=\"Upstream window size (bp) for 'sequence' column\")\n",
    "    ap.add_argument(\"--window-down\", type=int, default=100, help=\"Downstream window size (bp) for 'sequence' column\")\n",
    "\n",
    "    ap.add_argument(\"--motif-aware\", action=\"store_true\", help=\"Avoid negatives with strong PAS motifs upstream\")\n",
    "    ap.add_argument(\"--motif-upstream\", type=int, default=40, help=\"Upstream window for motif screening (bp)\")\n",
    "    ap.add_argument(\"--motif-list\", default=\"AAUAAA,AUUAAA,AGUAAA\", help=\"Comma-separated PAS-like hexamers (RNA alphabet allowed)\")\n",
    "\n",
    "    ap.add_argument(\"--seed\", type=int, default=42, help=\"Random seed\")\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    random.seed(args.seed)\n",
    "\n",
    "    # 1) Load chrom sizes\n",
    "    chrom_sizes = read_chrom_sizes(args.chrom_sizes)\n",
    "    sizes_keys = list(chrom_sizes.keys())\n",
    "\n",
    "    # 2) Build chrom mapper by peeking at BED chrom names\n",
    "    bed_chroms = set()\n",
    "    with open(args.positives) as f:\n",
    "        for line in f:\n",
    "            s = line.strip()\n",
    "            if not s or s.startswith(\"#\") or s.startswith(\"track\"):\n",
    "                continue\n",
    "            rec = parse_bed_line(s)\n",
    "            if rec is None:\n",
    "                continue\n",
    "            bed_chroms.add(rec[0])\n",
    "            if len(bed_chroms) >= 2000:\n",
    "                break\n",
    "    bed_chroms = sorted(bed_chroms)\n",
    "\n",
    "    chrom_mapper = build_bed_chrom_mapper(sizes_keys, bed_chroms)\n",
    "\n",
    "    # 3) Read positives (normalized + filtered)\n",
    "    pos_by_chrom = read_bed_points(\n",
    "        args.positives,\n",
    "        chrom_mapper=chrom_mapper,\n",
    "        primary_only=args.primary_only,\n",
    "        skip_alt=args.skip_alt,\n",
    "        assume_strand_plus_if_missing=True,\n",
    "    )\n",
    "\n",
    "    # 4) Optional mask\n",
    "    mask_by_chrom = None\n",
    "    if args.mask_bed:\n",
    "        mask_by_chrom = read_bed_regions(\n",
    "            args.mask_bed,\n",
    "            chrom_mapper=chrom_mapper,\n",
    "            primary_only=args.primary_only,\n",
    "            skip_alt=args.skip_alt,\n",
    "        )\n",
    "\n",
    "    # 5) Build positive buffers\n",
    "    buffers_by_chrom = {\n",
    "        chrom: build_positive_buffers([p for p,_,_ in plist], args.min_distance)\n",
    "        for chrom, plist in pos_by_chrom.items()\n",
    "    }\n",
    "\n",
    "    # 6) FASTA / pyfaidx -> build a handle and detect its chrom style\n",
    "    fasta_handle = None\n",
    "    fasta_target_has_chr = None\n",
    "    if args.fasta:\n",
    "        try:\n",
    "            from pyfaidx import Fasta  # type: ignore\n",
    "            fasta_handle = Fasta(str(args.fasta), as_raw=True, sequence_always_upper=True)\n",
    "            fasta_target_has_chr = fasta_has_chr_prefix(fasta_handle)\n",
    "        except Exception as e:\n",
    "            print(\"[WARN] Could not import/use pyfaidx; sequence and motif-aware filtering will be skipped.\", e)\n",
    "            fasta_handle = None\n",
    "            fasta_target_has_chr = None\n",
    "            args.motif_aware = False\n",
    "\n",
    "    motifs = [m.strip() for m in args.motif_list.split(\",\") if m.strip()]\n",
    "\n",
    "    # 7) Prepare output rows: positives first\n",
    "    out_rows = []\n",
    "    n_pos = 0\n",
    "    for chrom, plist in pos_by_chrom.items():\n",
    "        chrom_len = chrom_sizes.get(chrom)\n",
    "        for pos, strand, name in plist:\n",
    "            seq = fetch_window_seq(\n",
    "                fasta_handle, chrom, pos, strand,\n",
    "                args.window_up, args.window_down, chrom_len,\n",
    "                fasta_target_has_chr\n",
    "            )\n",
    "            out_rows.append({\n",
    "                \"chrom\": chrom,\n",
    "                \"pos\": pos,\n",
    "                \"strand\": strand,\n",
    "                \"label\": 1,\n",
    "                \"sequence\": seq,\n",
    "                \"source_id\": name,\n",
    "                \"region_id\": \"\",\n",
    "                \"notes\": \"\"\n",
    "            })\n",
    "            n_pos += 1\n",
    "\n",
    "    # 8) Sample negatives\n",
    "    n_neg = 0\n",
    "    n_skipped_chrom = 0\n",
    "    for chrom, plist in pos_by_chrom.items():\n",
    "        chrom_len = chrom_sizes.get(chrom, None)\n",
    "        if chrom_len is None:\n",
    "            print(f\"[WARN] chrom {chrom} not found in chrom sizes; skipping negatives for this chrom.\")\n",
    "            n_skipped_chrom += 1\n",
    "            continue\n",
    "\n",
    "        buffers = buffers_by_chrom[chrom]\n",
    "        mask = mask_by_chrom.get(chrom, []) if mask_by_chrom else None\n",
    "\n",
    "        for pos, strand, name in plist:\n",
    "            to_add = args.k_neg\n",
    "            attempts = 0\n",
    "            while to_add > 0 and attempts < 5000:\n",
    "                attempts += 1\n",
    "\n",
    "                # sample candidate\n",
    "                if mask:\n",
    "                    start, end, rid = random.choice(mask)\n",
    "                    if end - start <= 1:\n",
    "                        continue\n",
    "                    cand = random.randint(start, end - 1)\n",
    "                    cand_region = rid\n",
    "                else:\n",
    "                    cand = random.randint(0, chrom_len - 1)\n",
    "                    cand_region = \"\"\n",
    "\n",
    "                # distance from any positive\n",
    "                if contains_pos(buffers, cand):\n",
    "                    continue\n",
    "\n",
    "                # motif-aware upstream screen\n",
    "                if args.motif_aware and motif_present_upstream(\n",
    "                    fasta_handle, chrom, cand, strand,\n",
    "                    args.motif_upstream, motifs, fasta_target_has_chr\n",
    "                ):\n",
    "                    continue\n",
    "\n",
    "                seq = fetch_window_seq(\n",
    "                    fasta_handle, chrom, cand, strand,\n",
    "                    args.window_up, args.window_down, chrom_len,\n",
    "                    fasta_target_has_chr\n",
    "                )\n",
    "                out_rows.append({\n",
    "                    \"chrom\": chrom,\n",
    "                    \"pos\": cand,\n",
    "                    \"strand\": strand,\n",
    "                    \"label\": 0,\n",
    "                    \"sequence\": seq,\n",
    "                    \"source_id\": \"\",\n",
    "                    \"region_id\": cand_region,\n",
    "                    \"notes\": \"neg\"\n",
    "                })\n",
    "                n_neg += 1\n",
    "                to_add -= 1\n",
    "\n",
    "            if to_add > 0:\n",
    "                print(f\"[WARN] Only generated {args.k_neg - to_add}/{args.k_neg} negatives for {chrom}:{pos}{strand} after {attempts} attempts.\")\n",
    "\n",
    "    # 9) Write CSV\n",
    "    fieldnames = [\"chrom\",\"pos\",\"strand\",\"label\",\"sequence\",\"source_id\",\"region_id\",\"notes\"]\n",
    "    with open(args.out, \"w\", newline=\"\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        w.writeheader()\n",
    "        for r in out_rows:\n",
    "            w.writerow(r)\n",
    "\n",
    "    print(f\"[OK] Wrote {len(out_rows)} rows (pos+neg) to {args.out}  |  positives={n_pos}, negatives={n_neg}, skipped_chroms={n_skipped_chrom}\")\n",
    "    if n_neg == 0:\n",
    "        print(\"[HINT] If negatives are zero, ensure chromosome styles match (chr vs no-chr) and consider --primary-only/--skip-alt.\")\n",
    "    if fasta_handle is None:\n",
    "        print(\"[HINT] No FASTA provided or pyfaidx unavailable: 'sequence' column will be empty. Pass --fasta hg38.fa to populate it.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Wrote 1137216 rows (pos+neg) to apasites_with_negatives.csv  |  positives=568608, negatives=568608, skipped_chroms=0\n"
     ]
    }
   ],
   "source": [
    "# !pip install pyfaidx  # if needed\n",
    "\n",
    "import os, shlex, sys\n",
    "positives_bed = \"polyasite_hg38_clusters.bed\"\n",
    "chrom_sizes   = \"hg38.chrom.sizes\"\n",
    "out_csv       = \"apasites_with_negatives.csv\"\n",
    "hg38_fasta    = \"hg38.fa\"\n",
    "\n",
    "args = f\"\"\"\n",
    "--positives {positives_bed}\n",
    "--chrom-sizes {chrom_sizes}\n",
    "--out {out_csv}\n",
    "--k-neg 1\n",
    "--min-distance 200\n",
    "--primary-only\n",
    "--skip-alt\n",
    "--fasta {hg38_fasta}\n",
    "--window-up 200\n",
    "--window-down 100\n",
    "\"\"\".strip()\n",
    "\n",
    "for p in [positives_bed, chrom_sizes, hg38_fasta]:\n",
    "    if not os.path.exists(p):\n",
    "        raise FileNotFoundError(f\"Path not found: {p}\")\n",
    "\n",
    "sys.argv = [\"generate_negatives.py\"] + shlex.split(args)\n",
    "main() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unset GITHUB_TOKEN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
